import { useState, useRef, useEffect } from 'react';
import { ArrowLeft, Send, Volume2, Mic } from 'lucide-react';
import dinoImage from 'figma:asset/3a519b4fad679bec0e5a1851cb49a7ecc7330095.png';
import { useSpeechRecognition } from '../hooks/useSpeechRecognition';

interface ChatLearningProps {
  onBack: () => void;
}

interface Message {
  id: number;
  text: string;
  sender: 'user' | 'ai';
  translation?: string;
  audioText?: string;
}

export function ChatLearning({ onBack }: ChatLearningProps) {
  const [messages, setMessages] = useState<Message[]>([
    {
      id: 1,
      text: "Bonjour! Je suis DinoLingo, ton assistant d'apprentissage du franÃ§ais!",
      sender: 'ai',
      translation: "Hello! I'm DinoLingo, your French learning assistant!",
    },
    {
      id: 2,
      text: "Let's start with some basics. Click on a phrase below to practice:",
      sender: 'ai',
    },
  ]);
  const [inputValue, setInputValue] = useState('');
  const messagesEndRef = useRef<HTMLDivElement>(null);
  const nextId = useRef<number>(3); // id generator (initial messages use 1..2)
  
  // Speech recognition hook
  const {
    transcript,
    isListening,
    isSupported: isSpeechSupported,
    startListening,
    stopListening,
    resetTranscript,
  } = useSpeechRecognition({
    lang: 'fr-FR', // French language for learning
    continuous: false,
    interimResults: true,
  });

  const practiceWords = [
    { french: 'Bonjour', english: 'Hello' },
    { french: 'Merci', english: 'Thank you' },
    { french: 'Au revoir', english: 'Goodbye' },
    { french: 'Comment Ã§a va?', english: 'How are you?' },
  ];

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  };

  useEffect(() => {
    scrollToBottom();
  }, [messages]);

  // Update input when speech transcript changes
  useEffect(() => {
    if (transcript) {
      setInputValue(transcript);
    }
  }, [transcript]);

  const handleSpeechToggle = () => {
    if (isListening) {
      stopListening();
    } else {
      resetTranscript();
      setInputValue('');
      startListening();
    }
  };

  // helper: call backend teach endpoint
  const callTeachApi = async (messageText: string) => {
    try {
      const res = await fetch('http://127.0.0.1:8000/teach/chat', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ message: messageText }),
      });
      if (!res.ok) {
        const text = await res.text();
        throw new Error(`API error: ${res.status} ${text}`);
      }
      const data = await res.json();
      return data as { response: string; translation?: string | null; audioText?: string | null };
    } catch (err) {
      console.error(err);
      return { response: `Error contacting teacher: ${String(err)}` };
    }
  };

  const getVoices = () =>
    new Promise<SpeechSynthesisVoice[]>((resolve) => {
      const synth = window.speechSynthesis;
      let voices = synth.getVoices();
      if (voices.length) return resolve(voices);
      const handler = () => {
        voices = synth.getVoices();
        synth.removeEventListener('voiceschanged', handler);
        resolve(voices);
      };
      synth.addEventListener('voiceschanged', handler);
      // fallback timeout in case event never fires
      setTimeout(() => resolve(synth.getVoices()), 1000);
    });

  // æ˜¯å¦å­˜åœ¨æ³•è¯­ TTS voiceï¼ˆç”¨äºç¦ç”¨éŸ³é¢‘åŠŸèƒ½ï¼‰
  const [frenchTTSAvailable, setFrenchTTSAvailable] = useState<boolean>(true);

  // ç»„ä»¶æŒ‚è½½æ—¶æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ³•è¯­ voiceï¼›è‹¥ä¸å­˜åœ¨åˆ™ç¦ç”¨éŸ³é¢‘å¹¶è®°å½•æ—¥å¿—
  useEffect(() => {
    if (!('speechSynthesis' in window)) {
      console.warn('Web Speech API not supported - TTS disabled');
      setFrenchTTSAvailable(false);
      return;
    }
    let mounted = true;
    getVoices().then((voices) => {
      if (!mounted) return;
      const hasFrench = voices.some((v) => v.lang?.toLowerCase().startsWith('fr'));
      if (!hasFrench) {
        console.warn('No French TTS voices available - audio disabled');
      } else {
        console.log('French TTS voice available');
      }
      setFrenchTTSAvailable(hasFrench);
    }).catch((e) => {
      console.warn('Error fetching voices, disabling TTS', e);
      setFrenchTTSAvailable(false);
    });
    return () => { mounted = false; };
  }, []);

  // ç®€å•æ³•è¯­æ£€æµ‹ï¼šæ£€æŸ¥æ³•è¯­ç‰¹æœ‰å­—ç¬¦æˆ–å¸¸è§æ³•è¯­è¯æ±‡ï¼ˆå¯å‘å¼ï¼Œä¸ä¿è¯ 100% å‡†ç¡®ï¼‰
  const isFrench = (text?: string | null) => {
    if (!text) return false;
    const t = text.toLowerCase();
    // å¸¸è§å¸¦é‡éŸ³çš„æ³•è¯­å­—ç¬¦
    const frenchCharRe = /[Ã©Ã¨ÃªÃ«Ã Ã¢Ã®Ã¯Ã´Ã¶Ã¹Ã»Ã§Å“Ã¦]/i;
    if (frenchCharRe.test(text)) return true;
    // å¸¸è§æ³•è¯­è¯æ±‡å¯å‘å¼åŒ¹é…
    const commonFrenchWords = ['bonjour', 'merci', 'au revoir', 'comment', 'Ã§a', "s'il", 'oui', 'non', 'monsieur', 'madame'];
    return commonFrenchWords.some((w) => t.includes(w));
  };

  const playAudio = async (text?: string | null) => {
    if (!text) return;
    // ä»…æ’­æ”¾è¢«æ£€æµ‹ä¸ºæ³•è¯­çš„æ–‡æœ¬
    if (!isFrench(text)) {
      console.warn('Audio not played: text not detected as French.');
      return;
    }
    // å¦‚æœæ²¡æœ‰æ³•è¯­ TTS voiceï¼Œåˆ™ç¦ç”¨æ’­æ”¾
    if (!frenchTTSAvailable) {
      console.warn('Audio not played: no French TTS voice available.');
      return;
    }
    // browser TTS
    if ('speechSynthesis' in window) {
      try {
        const voices = await getVoices();
        // prefer French voices
        const voice =
          voices.find((v) => v.lang?.toLowerCase().startsWith('fr')) ||
          voices.find((v) => v.lang === 'fr-FR') ||
          voices[0];

        const utter = new SpeechSynthesisUtterance(text);
        utter.lang = 'fr-FR';
        if (voice) utter.voice = voice;
        utter.rate = 0.95; // æ…¢ä¸€ç‚¹æ›´æ¸…æ™°
        utter.pitch = 1;
        utter.volume = 1;

        utter.onstart = () => {
          // å¯åœ¨æ­¤æ›´æ–° UIï¼ˆä¾‹å¦‚æ˜¾ç¤ºæ­£åœ¨æ’­æ”¾ï¼‰
        };
        utter.onend = () => {
          // å¯åœ¨æ­¤æ›´æ–° UIï¼ˆä¾‹å¦‚å…³é—­æ’­æ”¾æŒ‡ç¤ºå™¨ï¼‰
        };
        utter.onerror = (e) => {
          console.warn('TTS error', e);
        };

        window.speechSynthesis.cancel(); // å–æ¶ˆå½“å‰æ’­æ”¾ï¼Œç¡®ä¿æœ€æ–°æ–‡æœ¬æ’­æ”¾
        window.speechSynthesis.speak(utter);
        return;
      } catch (e) {
        console.warn('TTS failed, falling back to server audio', e);
      }
    } else {
      console.warn('Web Speech API not supported in this browser');
    }
  };
  
  const handleSendMessage = async () => {
    if (!inputValue.trim()) return;

    const userMessage: Message = {
      id: nextId.current++,
      text: inputValue,
      sender: 'user',
    };

    setMessages((prev) => [...prev, userMessage]);
    setInputValue('');

    // call backend
    const data = await callTeachApi(userMessage.text);

    const aiMessage: Message = {
      id: nextId.current++,
      text: data.response ?? 'No response',
      sender: 'ai',
      translation: data.translation ?? undefined,
      // åªæœ‰åç«¯è¿”å›çš„ audioText è¢«æ£€æµ‹ä¸ºæ³•è¯­æ—¶æ‰ä¿ç•™ï¼Œå¦åˆ™ä¸æä¾›éŸ³é¢‘
      audioText: isFrench(data.audioText) ? (data.audioText as string) : undefined,
    };

    setMessages((prev) => [...prev, aiMessage]);
  };

  const handlePracticeWord = async (word: { french: string; english: string }) => {
    const userMessage: Message = {
      id: nextId.current++,
      text: word.french,
      sender: 'user',
    };
    setMessages((prev) => [...prev, userMessage]);

    const data = await callTeachApi(word.french);

    const aiMessage: Message = {
      id: nextId.current++,
      text: data.response ?? `Excellent! "${word.french}" means "${word.english}".`,
      sender: 'ai',
      translation: data.translation ?? `\"${word.french}\" = \"${word.english}\"`,
      // ä¼˜å…ˆä½¿ç”¨åç«¯æä¾›ä¸”è¢«æ£€æµ‹ä¸ºæ³•è¯­çš„ audioTextï¼Œå¦åˆ™ä½¿ç”¨æœ¬åœ°çš„æ³•è¯­çŸ­è¯­
      audioText: isFrench(data.audioText) ? (data.audioText as string) : word.french,
    };
    setMessages((prev) => [...prev, aiMessage]);
  };

  const handleKeyPress = (e: React.KeyboardEvent) => {
    if (e.key === 'Enter') {
      handleSendMessage();
    }
  };

  return (
    <div className="h-screen flex flex-col overflow-hidden" style={{ backgroundColor: '#F5E5C7' }}>
      {/* Header */}
      <div className="flex items-center justify-between p-3 sm:p-4 border-b-2 flex-shrink-0" style={{ borderColor: '#B8621B' }}>
        <button
          onClick={onBack}
          className="flex items-center gap-2 text-sm sm:text-base hover:opacity-70 transition-opacity"
          style={{ color: '#B8621B' }}
        >
          <ArrowLeft className="w-4 h-4 sm:w-5 sm:h-5" />
          <span>Back to Menu</span>
        </button>
        <div className="flex items-center gap-2">
          <img src={dinoImage} alt="DinoLingo" className="w-8 h-8 sm:w-10 sm:h-10 object-contain" />
          <span className="text-sm sm:text-base" style={{ color: '#B8621B' }}>DinoLingo Chat</span>
        </div>
      </div>

      {/* Chat Messages */}
      <div className="flex-1 overflow-y-auto p-4 space-y-4">
        {messages.map((message) => (
          <div
            key={message.id}
            className={`flex ${message.sender === 'user' ? 'justify-end' : 'justify-start'}`}
          >
            <div
              className={`max-w-[80%] sm:max-w-[70%] rounded-2xl p-3 sm:p-4 ${
                message.sender === 'user' ? 'rounded-br-sm' : 'rounded-bl-sm'
              }`}
              style={{
                backgroundColor: message.sender === 'user' ? '#B8621B' : '#FFD7B5',
                color: message.sender === 'user' ? 'white' : '#B8621B',
              }}
            >
              <p className="text-sm sm:text-base">{message.text}</p>
              {message.translation && (
                <p className="text-xs sm:text-sm mt-2 opacity-80">{message.translation}</p>
              )}
              {/* ä»…å½“ audioText å­˜åœ¨ä¸”è¢«æ£€æµ‹ä¸ºæ³•è¯­æ—¶æ˜¾ç¤ºæ’­æ”¾æŒ‰é’® */}
              {message.audioText && isFrench(message.audioText) && frenchTTSAvailable && (
                <button
                  className="mt-2 flex items-center gap-1 text-xs sm:text-sm opacity-80 hover:opacity-100"
                  onClick={() => playAudio(message.audioText)}
                >
                  <Volume2 className="w-3 h-3 sm:w-4 sm:h-4" />
                  <span>Listen</span>
                </button>
              )}
            </div>
          </div>
        ))}

        {/* Practice Words Section */}
        {messages.length <= 5 && (
          <div className="flex flex-wrap gap-2 justify-center mt-4">
            {practiceWords.map((word, index) => (
              <button
                key={index}
                onClick={() => handlePracticeWord(word)}
                className="px-3 py-2 sm:px-4 sm:py-2 rounded-xl border-2 text-xs sm:text-sm hover:scale-105 transition-transform"
                style={{
                  backgroundColor: 'white',
                  borderColor: '#B8621B',
                  color: '#B8621B',
                }}
              >
                {word.french}
              </button>
            ))}
          </div>
        )}

        <div ref={messagesEndRef} />
      </div>

      {/* Input Area */}
      <div className="p-3 sm:p-4 border-t-2 flex-shrink-0" style={{ borderColor: '#B8621B', backgroundColor: 'white' }}>
        <div className="flex gap-2">
          <input
            type="text"
            value={inputValue}
            onChange={(e) => setInputValue(e.target.value)}
            onKeyPress={handleKeyPress}
            placeholder={isListening ? "Listening..." : "Type a message or click a phrase above..."}
            className="flex-1 px-3 py-2 sm:px-4 sm:py-3 rounded-xl border-2 text-sm sm:text-base focus:outline-none focus:ring-2 transition-all"
            style={{
              borderColor: isListening ? '#22C55E' : '#FFD7B5',
              color: '#B8621B',
            }}
          />
          {isSpeechSupported && (
            <button
              onClick={handleSpeechToggle}
              className={`w-10 h-10 sm:w-12 sm:h-12 rounded-xl flex items-center justify-center hover:opacity-90 transition-opacity flex-shrink-0 ${
                isListening ? 'animate-pulse' : ''
              }`}
              style={{
                backgroundColor: isListening ? '#22C55E' : '#B8621B',
              }}
              title={isListening ? 'Stop listening' : 'Start voice input'}
            >
              <Mic className="w-4 h-4 sm:w-5 sm:h-5 text-white" />
            </button>
          )}
          <button
            onClick={handleSendMessage}
            className="w-10 h-10 sm:w-12 sm:h-12 rounded-xl flex items-center justify-center hover:opacity-90 transition-opacity flex-shrink-0"
            style={{ backgroundColor: '#B8621B' }}
          >
            <Send className="w-4 h-4 sm:w-5 sm:h-5 text-white" />
          </button>
        </div>
        {isListening && (
          <div className="mt-2 text-xs text-center" style={{ color: '#22C55E' }}>
            ğŸ¤ Listening... Speak now!
          </div>
        )}
      </div>
    </div>
  );
}
